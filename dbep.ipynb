{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from itertools import combinations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_synthesis = dict()\n",
    "canonical_list = []\n",
    "domkniecia = {}\n",
    "key_attributes = set()\n",
    "non_key_attributes = set()\n",
    "minimal_keys = set()\n",
    "super_keys = set()\n",
    "closure_string = \"\"\n",
    "base_min = []\n",
    "destroy_2PN = []\n",
    "destroy_3PN = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combo(attributes):\n",
    "    length = len(attributes)\n",
    "    temp = []\n",
    "    for i in range(length):\n",
    "        if i == 0:\n",
    "            for j in attributes:\n",
    "                temp.append(j)\n",
    "        else:\n",
    "            combs = combinations(attributes, i+1)\n",
    "            for combo in combs:\n",
    "                combo = sorted(combo)\n",
    "                temp.append(','.join(combo))\n",
    "    sorted_alphabetically = sorted(temp)\n",
    "    sorted_len_alpha = sorted(sorted_alphabetically,key=len)\n",
    "    return sorted_len_alpha\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# a function that returns a SET that is the complement of the given closure\n",
    "def closer(combination, relations):\n",
    "    closing_set = set(combination)\n",
    "    basic_length = len(closing_set)\n",
    "    for relation in relations:\n",
    "        set_attr = set(relation[0].split(\",\"))\n",
    "        if set_attr.issubset(closing_set):\n",
    "            add = relation[1]\n",
    "            closing_set.add(add)\n",
    "            if len(closing_set) != basic_length:\n",
    "                return closer(closing_set, relations)\n",
    "    return_set = sorted(closing_set)\n",
    "    return return_set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function remembering all closures and determining all keys without division into min. candidate key and superkeys\n",
    "\n",
    "def keys_gen(attributes, relations):\n",
    "    all_combinations = combo(attributes)\n",
    "    all_closures = []\n",
    "    all_keys = []\n",
    "    for combination in all_combinations:\n",
    "        to_close = combination.split(\",\")\n",
    "        closure = closer(to_close, relations)\n",
    "        # save all closures\n",
    "        all_closures.append(closure)\n",
    "        # recording of all keys (without division into minimum candidate keys and superkeys)\n",
    "        if(len(closure) == len(attributes)):\n",
    "            all_keys.append(combination)\n",
    "    return all_keys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function that determines the set of minimal candidate keys and superkeys from the set of all keys\n",
    "def extract_minimal(all_keys_set):\n",
    "    global minimal_keys\n",
    "    global super_keys\n",
    "    temp_all = set(all_keys_set)\n",
    "    i = 0\n",
    "    for y in all_keys_set:\n",
    "        i = i + 1\n",
    "        for x in all_keys_set[i:]:\n",
    "            subset_candidat = set(y.split(\",\"))\n",
    "            master_set = set(x.split(\",\"))\n",
    "            if(subset_candidat.issubset(master_set) and subset_candidat != master_set):\n",
    "                all_keys_set.remove(x)\n",
    "    minimal_keys = sorted(set(all_keys_set))\n",
    "    super_keys = sorted(sorted(temp_all.difference(minimal_keys)),key=len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to print all closures\n",
    "def list_closure(attributes, relations):\n",
    "    # set of all closures\n",
    "\n",
    "    global minimal_keys\n",
    "    global super_keys\n",
    "    global closure_string\n",
    "    all_combinations = combo(attributes)\n",
    "    print(\"[CLOSURES]\")\n",
    "    for combination in all_combinations:\n",
    "        temp_attr = combination.split(',')\n",
    "        closure = closer(temp_attr, canonical_list)\n",
    "        closure_string = closure_string + \"\".join(closure)\n",
    "        print('{' + combination.replace(\",\",\", \") + '}+ = {' + \", \".join(closure).strip() + \"}\" , end=\"\")\n",
    "        if(combination in minimal_keys):\n",
    "            print(\"          <----- MINIMUM CANDIDATE KEY\")\n",
    "        elif(combination in super_keys):\n",
    "            print(\"          <----- SUPER KEY\")\n",
    "        else:\n",
    "            print(\"\")\n",
    "        # check if closure is a key\n",
    "    return key_attributes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function that generates a string that is a combination of all closures - needed to verify whether the attribute can be removed\n",
    "\n",
    "def generate_closure_string(attributes, relations):\n",
    "    closure_str = \"\"\n",
    "    all_combinations = combo(attributes)\n",
    "    for combination in all_combinations:\n",
    "        temp_attr = combination.split(',')\n",
    "        closure = closer(temp_attr, relations)\n",
    "        closure_str= closure_str + \"\".join(closure)\n",
    "    return closure_str\n",
    "\n",
    "# function to remove redundant attributes from the left side\n",
    "\n",
    "def delete(input_list):\n",
    "    global canonical_list\n",
    "    global attributes\n",
    "    global base_min\n",
    "    global closure_string\n",
    "    default_relations = list(input_list)\n",
    "    for x in input_list:\n",
    "        defaultLeft = x[0].split(\",\")\n",
    "        if(len(defaultLeft) > 1):\n",
    "            for i in range(len(defaultLeft)):\n",
    "                if(len(x[0]) == 1):\n",
    "                    break\n",
    "                defaultLeft = x[0].split(\",\")\n",
    "                defaultLeft.pop(i)\n",
    "                new_relation = [\",\".join(defaultLeft),x[1]]\n",
    "                temp_list = list(default_relations)\n",
    "                temp_list.remove(x)\n",
    "                temp_list.append(new_relation)\n",
    "                # I check if the attributes on the left side of the closure are the same after deleting, if so, it means that you can remove the attributes and try to remove the next one (recursively)\n",
    "                \n",
    "                if(closure_string == generate_closure_string(attributes, temp_list)):\n",
    "                    for x in temp_list:\n",
    "                        print(x[0] + \" -> \" + x[1])\n",
    "                    base_min = list(temp_list)\n",
    "                    return delete(temp_list)\n",
    "        base_min = list(default_relations)\n",
    "# a function that removes redundant functional compounds - I try to remove each one in turn, if it does not affect the closures in any way, I remove\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def del_relations():\n",
    "    global attributes\n",
    "    global base_min\n",
    "    global closure_string\n",
    "    temp_relations = list(base_min)\n",
    "    for x in base_min:\n",
    "        if x in temp_relations:\n",
    "            temp_relations.remove(x)\n",
    "            generated_closure = generate_closure_string(attributes,temp_relations)\n",
    "            if(closure_string == generated_closure):\n",
    "                base_min.remove(x)\n",
    "            temp_relations = list(base_min)\n",
    "\n",
    "# auxiliary function for determining the minimum base\n",
    "def minimal_base(canonical_relations):\n",
    "    global base_min\n",
    "    global canonical_list\n",
    "    # remove attributes from the left\n",
    "    delete(canonical_relations)\n",
    "    # usuwanie zbędnych zależności\n",
    "    del_relations()\n",
    "    # removing unnecessary dependencies\n",
    "    b_set = set(tuple(x) for x in base_min)\n",
    "    canonical_list = [list(x) for x in b_set if x[0] != x[1]]\n",
    "    if(canonical_list):\n",
    "        for x in sorted(sorted(canonical_list), key=len):\n",
    "            print(x[0] + \" -> \" + x[1])\n",
    "    else:\n",
    "        print(\"brak\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# padding for 2PN\n",
    "def closer2PN(subset):\n",
    "    global destroy_2PN\n",
    "    global non_key_attributes\n",
    "    global base_min\n",
    "    # given proper subset of key\n",
    "    closing_set = set(subset)\n",
    "    for relation in base_min:\n",
    "        # left side of relation\n",
    "        left_set = set(relation[0].split(\",\"))\n",
    "\n",
    "# if the left side is a subset of the key i.e. it is its proper subset and the right side is not a key attribute then the dependency breaks 2PN\n",
    "        if(left_set.issubset(closing_set) and relation[1] in non_key_attributes and left_set != closing_set):\n",
    "            destroy_2PN.append(relation)\n",
    "\n",
    "# send each minimal key of the relation and check if the left side is a subset of the key, then if the right side is a non-key attribute\n",
    "\n",
    "def is2PN():\n",
    "    global base_min\n",
    "    global minimal_keys\n",
    "    global destroy_2PN\n",
    "    for key in minimal_keys:\n",
    "        subsets = combo(key.split(\",\"))\n",
    "        for subset in subsets:\n",
    "            closer2PN(subset.split(\",\"))\n",
    "    b_set = set(tuple(x) for x in destroy_2PN)\n",
    "    destroy_2PN = [list(x) for x in b_set if x[0] != x[1]]\n",
    "    if(destroy_2PN):\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "# test for 3PN using the negation of the alternative ~(p or q or r)\n",
    "def is3PN():\n",
    "    global base_min\n",
    "    global key_attributes\n",
    "    global super_keys\n",
    "    global destroy_3PN\n",
    "    for relation in base_min:\n",
    "        left = relation[0].split(\",\")\n",
    "        if (relation[1] not in left) and (relation[1] not in key_attributes) and (left not in super_keys):\n",
    "            destroy_3PN.append(relation)\n",
    "    b_set = set(tuple(x) for x in destroy_3PN)\n",
    "    destroy_3PN = [list(x) for x in b_set if x[0] != x[1]]\n",
    "    if(destroy_3PN):\n",
    "        return False\n",
    "    else:\n",
    "        return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for determining and listing key and non-key attributes\n",
    "def attributes_specification():\n",
    "    global minimal_keys\n",
    "    global super_keys\n",
    "    global non_key_attributes\n",
    "    global key_attributes\n",
    "    key_attrs = set()\n",
    "    non_key_attrs = set()\n",
    "    for x in minimal_keys:\n",
    "        x = x.split(\",\")\n",
    "        for y in x:\n",
    "            key_attrs.add(y)\n",
    "    key_attributes = sorted(key_attrs)\n",
    "    print(\"Key attributes: \",end=\"\")\n",
    "    if(not len(key_attrs)):\n",
    "        print(\"lack\")\n",
    "    else:\n",
    "        print(\", \".join(sorted(key_attrs)))\n",
    "    non_key_attrs = sorted(attributes.difference(key_attrs))\n",
    "    print(\"Non-key attributes: \",end=\"\")\n",
    "    if(not len(non_key_attrs)):\n",
    "        print(\"lack\")\n",
    "    else:\n",
    "        print(\", \".join(sorted(non_key_attrs)))\n",
    "    non_key_attributes = non_key_attrs\n",
    "\n",
    "# the function does not check if there is a scheme containing any of the keys and does not combine any of the keys - at the moment it only divides\n",
    "# schemes are stored in the dictionary as 'U': 'F', the right side is a set\n",
    "def synthesis_closure(uni_and_func):\n",
    "    global post_synthesis\n",
    "    final_closure = []\n",
    "    final_relations = []\n",
    "    keys = []\n",
    "    move_relations = []\n",
    "    for x in uni_and_func:\n",
    "        closure = set(x.split(\",\"))\n",
    "        relations = set()\n",
    "        # input dependency with the same attribute on the left\n",
    "        for y in uni_and_func.values():\n",
    "            # step over them and add to the closure\n",
    "            for z in y:\n",
    "                if z[0] == x:\n",
    "                    closure.add(z[1])\n",
    "                    relation = z[0] + \" -> \" + z[1]\n",
    "                    relations.add(relation)\n",
    "        # print(post_synthesis)\n",
    "        # add callbacks\n",
    "        for y in uni_and_func.values():\n",
    "            for z in y:\n",
    "                if z[1] == x:\n",
    "                    if(set(z[0].split(\",\")).issubset(closure)):\n",
    "                        relation = z[0] + ' -> '+ z[1]\n",
    "                        relations.add(relation)\n",
    "        # IMPORTANT CONTROL BECAUSE IT WAS OVERWRITING SOMETIMES\n",
    "        if(\",\".join(sorted(closure)) in post_synthesis.keys()):\n",
    "            move_relations = post_synthesis[\",\".join(sorted(closure))]\n",
    "            move_relations = set(move_relations)\n",
    "            for x in move_relations:\n",
    "                relations.add(x)\n",
    "        post_synthesis[\",\".join(sorted(closure))] = relations\n",
    "        #\n",
    "        if(move_relations):\n",
    "            post_synthesis[\",\".join(sorted(closure))] = relations\n",
    "        # print(post_synthesis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the function checks if there are schemes that are included in each other and if you need to add a scheme with U = key F = none\n",
    "def synthesis_final():\n",
    "    global post_synthesis\n",
    "    global minimal_keys\n",
    "    key_in = False\n",
    "    # print(post_synthesis)\n",
    "    # check if the key is a member of any schema, if not add it\n",
    "    for x in minimal_keys:\n",
    "        x = set(x.split(\",\"))\n",
    "        for y in post_synthesis.keys():\n",
    "            y = set(y.split(\",\"))\n",
    "            if(x.issubset(y)):\n",
    "                key_in = True\n",
    "    if(not key_in):\n",
    "        rand_key = minimal_keys[0]\n",
    "        post_synthesis[rand_key] = \"lack\"\n",
    "    # print(post_synthesis)\n",
    "    # check if one schema is a subset of another\n",
    "    for x in post_synthesis.keys():\n",
    "        x_subset = set(x.split(\",\"))\n",
    "        for y in post_synthesis.keys():\n",
    "            y_subset = set(y.split(\",\"))\n",
    "            if x_subset.issubset(y_subset) and x_subset != y_subset:\n",
    "                move_relations = post_synthesis[x]\n",
    "                post_synthesis[x] = ''\n",
    "                for z in move_relations:\n",
    "                    post_synthesis[y].add(z)\n",
    "                break\n",
    "    # print(post_synthesis)\n",
    "\n",
    "\n",
    "# print decomposition\n",
    "def synthesis(canonical_list,df):\n",
    "    # df = pd.read_csv(\"input.csv\")\n",
    "    global post_synthesis\n",
    "    uni_and_func = dict()\n",
    "    left_closures = set()\n",
    "    for x in canonical_list:\n",
    "        left_closures.add(x[0])\n",
    "        uni_and_func[x[0]] = list()\n",
    "    for x in canonical_list:\n",
    "        if x[0] in uni_and_func.keys():\n",
    "            uni_and_func[x[0]].append(x)\n",
    "    synthesis_closure(uni_and_func)\n",
    "    synthesis_final()\n",
    "    i = 0\n",
    "    for x in post_synthesis:\n",
    "        if post_synthesis[x] != '':\n",
    "            #print the table using create_table function\n",
    "            attributes_table_list =  x.split(\",\")\n",
    "            index = [ord(i)-65 for i in attributes_table_list]\n",
    "            create_table(df, index)\n",
    "            print(\"R\" + str(i) + \" = \" + \"(\" + \" U\" + str(i) + \" = \" + \"{\" + x + \"}, F\" + str(i) + \" = \" + str(post_synthesis[x]) + \" )\")\n",
    "            i = i + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the module which have tabulate function\n",
    "from tabulate import tabulate\n",
    "\n",
    "def create_table(df, index):\n",
    "    #print the table and beautify it\n",
    "    #get the list of the attributes from the index\n",
    "    attributes_total = list(df.columns)\n",
    "    table_attributes = [attributes_total[i] for i in index]\n",
    "    df = df[table_attributes]\n",
    "    #remove the duplicate rows and make the table\n",
    "    df = df.drop_duplicates()\n",
    "    #remove the index column\n",
    "    df = df.reset_index(drop=True)\n",
    "    print(tabulate(df,headers=table_attributes,tablefmt=\"grid\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The attributes are: A, B, C, D, E, F\n",
      "Action: \n",
      "1 - entering attributes and relationships manually\n",
      "2 - loading attributes and relationships from the file\n",
      "Type any other character to exit\n",
      "Enter the attributes in one line, separating only with a comma.\n",
      "Enter each functional dependency on a separate line. After entering all of them, also on a separate line, enter END to continue.\n",
      "When entering functional dependencies, keep the format: attributes/y -> attributes/y, i.e. A,B -> D,C\n",
      "Functional dependencies: \n",
      "--------------------------------------------------------------------------------------------------------------------------------\n",
      "[ANALYSIS - START]\n",
      "Attributes: A,B,C,D,E,F\n",
      "Functional dependencies: \n",
      "A->C\n",
      "C->D\n",
      "D->E\n",
      "E->F\n",
      "\n",
      "[VERIFICATION]\n",
      "Attributes with U: A, B, C, D, E, F\n",
      "Attributes from F: A, C, D, E, F\n",
      "There is at least one attribute in U that is not in F. Adds a trivial dependency.\n",
      "B -> B\n",
      "--------------------------------------------------------------------------------------------------------------------------------\n",
      "The attributes in F and U match. Verification successful.\n",
      "\n",
      "[CLOSURES]\n",
      "{A}+ = {A, C, D, E, F}\n",
      "{B}+ = {B}\n",
      "{C}+ = {C, D, E, F}\n",
      "{D}+ = {D, E, F}\n",
      "{E}+ = {E, F}\n",
      "{F}+ = {F}\n",
      "{A, B}+ = {A, B, C, D, E, F}          <----- MINIMUM CANDIDATE KEY\n",
      "{A, C}+ = {A, C, D, E, F}\n",
      "{A, D}+ = {A, C, D, E, F}\n",
      "{A, E}+ = {A, C, D, E, F}\n",
      "{A, F}+ = {A, C, D, E, F}\n",
      "{B, C}+ = {B, C, D, E, F}\n",
      "{B, D}+ = {B, D, E, F}\n",
      "{B, E}+ = {B, E, F}\n",
      "{B, F}+ = {B, F}\n",
      "{C, D}+ = {C, D, E, F}\n",
      "{C, E}+ = {C, D, E, F}\n",
      "{C, F}+ = {C, D, E, F}\n",
      "{D, E}+ = {D, E, F}\n",
      "{D, F}+ = {D, E, F}\n",
      "{E, F}+ = {E, F}\n",
      "{A, B, C}+ = {A, B, C, D, E, F}          <----- SUPER KEY\n",
      "{A, B, D}+ = {A, B, C, D, E, F}          <----- SUPER KEY\n",
      "{A, B, E}+ = {A, B, C, D, E, F}          <----- SUPER KEY\n",
      "{A, B, F}+ = {A, B, C, D, E, F}          <----- SUPER KEY\n",
      "{A, C, D}+ = {A, C, D, E, F}\n",
      "{A, C, E}+ = {A, C, D, E, F}\n",
      "{A, C, F}+ = {A, C, D, E, F}\n",
      "{A, D, E}+ = {A, C, D, E, F}\n",
      "{A, D, F}+ = {A, C, D, E, F}\n",
      "{A, E, F}+ = {A, C, D, E, F}\n",
      "{B, C, D}+ = {B, C, D, E, F}\n",
      "{B, C, E}+ = {B, C, D, E, F}\n",
      "{B, C, F}+ = {B, C, D, E, F}\n",
      "{B, D, E}+ = {B, D, E, F}\n",
      "{B, D, F}+ = {B, D, E, F}\n",
      "{B, E, F}+ = {B, E, F}\n",
      "{C, D, E}+ = {C, D, E, F}\n",
      "{C, D, F}+ = {C, D, E, F}\n",
      "{C, E, F}+ = {C, D, E, F}\n",
      "{D, E, F}+ = {D, E, F}\n",
      "{A, B, C, D}+ = {A, B, C, D, E, F}          <----- SUPER KEY\n",
      "{A, B, C, E}+ = {A, B, C, D, E, F}          <----- SUPER KEY\n",
      "{A, B, C, F}+ = {A, B, C, D, E, F}          <----- SUPER KEY\n",
      "{A, B, D, E}+ = {A, B, C, D, E, F}          <----- SUPER KEY\n",
      "{A, B, D, F}+ = {A, B, C, D, E, F}          <----- SUPER KEY\n",
      "{A, B, E, F}+ = {A, B, C, D, E, F}          <----- SUPER KEY\n",
      "{A, C, D, E}+ = {A, C, D, E, F}\n",
      "{A, C, D, F}+ = {A, C, D, E, F}\n",
      "{A, C, E, F}+ = {A, C, D, E, F}\n",
      "{A, D, E, F}+ = {A, C, D, E, F}\n",
      "{B, C, D, E}+ = {B, C, D, E, F}\n",
      "{B, C, D, F}+ = {B, C, D, E, F}\n",
      "{B, C, E, F}+ = {B, C, D, E, F}\n",
      "{B, D, E, F}+ = {B, D, E, F}\n",
      "{C, D, E, F}+ = {C, D, E, F}\n",
      "{A, B, C, D, E}+ = {A, B, C, D, E, F}          <----- SUPER KEY\n",
      "{A, B, C, D, F}+ = {A, B, C, D, E, F}          <----- SUPER KEY\n",
      "{A, B, C, E, F}+ = {A, B, C, D, E, F}          <----- SUPER KEY\n",
      "{A, B, D, E, F}+ = {A, B, C, D, E, F}          <----- SUPER KEY\n",
      "{A, C, D, E, F}+ = {A, C, D, E, F}\n",
      "{B, C, D, E, F}+ = {B, C, D, E, F}\n",
      "{A, B, C, D, E, F}+ = {A, B, C, D, E, F}          <----- SUPER KEY\n",
      "\n",
      "[DETERMINATION OF ATTRIBUTES]\n",
      "Key attributes: A, B\n",
      "Non-key attributes: C, D, E, F\n",
      "\n",
      "[MINIMUM BASE]\n",
      "A -> C\n",
      "C -> D\n",
      "D -> E\n",
      "E -> F\n",
      "\n",
      "[TEST ON 2PN]\n",
      "The relation is not in 2 normal form.\n",
      "For a relation to be in 2PN, it is necessary that each non-key attribute is fully functionally dependent on each key of that relation.\n",
      "In the given scheme, there is more pleasantly one partial functional dependency that violates 2PN.\n",
      "These dependencies are:\n",
      "A -> C\n",
      "\n",
      "For a relation to be in 3PN, it is necessary that, in addition to being in 2PN, each of its functional dependencies X -> Y has one of the following properties:\n",
      "\n",
      "(1) the relationship is trivial (Y is contained in X) or\n",
      "(2) X is a superkey or\n",
      "(3) Y is a key attribute\n",
      "            \n",
      "[TEST ON 3PN]\n",
      "The relation is not in 3 normal form. Dependencies that do not meet any of the above conditions are: \n",
      "C -> D\n",
      "E -> F\n",
      "D -> E\n",
      "A -> C\n",
      "\n",
      "[DECOMPOSITION BY SYNTHESIS]\n",
      "+----+--------------+-----------+\n",
      "|    | C            | D         |\n",
      "+====+==============+===========+\n",
      "|  0 | Capital      | Hospitals |\n",
      "+----+--------------+-----------+\n",
      "|  1 | Mumbai       | 6         |\n",
      "+----+--------------+-----------+\n",
      "|  2 | Jaipur       | 2         |\n",
      "+----+--------------+-----------+\n",
      "|  3 | Delhi        | 4         |\n",
      "+----+--------------+-----------+\n",
      "|  4 | Bhubhaneswar | 2         |\n",
      "+----+--------------+-----------+\n",
      "|  5 | Gandhinagar  | 4         |\n",
      "+----+--------------+-----------+\n",
      "R0 = ( U0 = {C,D}, F0 = {'C -> D'} )\n",
      "+----+------+-------+\n",
      "|    | E    | F     |\n",
      "+====+======+=======+\n",
      "|  0 | Labs | Tests |\n",
      "+----+------+-------+\n",
      "|  1 | 3    | 60    |\n",
      "+----+------+-------+\n",
      "|  2 | 1    | 20    |\n",
      "+----+------+-------+\n",
      "|  3 | 2    | 40    |\n",
      "+----+------+-------+\n",
      "|  4 | 2    | 20    |\n",
      "+----+------+-------+\n",
      "R1 = ( U1 = {E,F}, F1 = {'E -> F'} )\n",
      "+----+-----------+------+\n",
      "|    | D         | E    |\n",
      "+====+===========+======+\n",
      "|  0 | Hospitals | Labs |\n",
      "+----+-----------+------+\n",
      "|  1 | 6         | 3    |\n",
      "+----+-----------+------+\n",
      "|  2 | 2         | 1    |\n",
      "+----+-----------+------+\n",
      "|  3 | 4         | 2    |\n",
      "+----+-----------+------+\n",
      "R2 = ( U2 = {D,E}, F2 = {'D -> E'} )\n",
      "+----+-------------+--------------+\n",
      "|    | A           | C            |\n",
      "+====+=============+==============+\n",
      "|  0 | State       | Capital      |\n",
      "+----+-------------+--------------+\n",
      "|  1 | Maharashtra | Mumbai       |\n",
      "+----+-------------+--------------+\n",
      "|  2 | Rajasthan   | Jaipur       |\n",
      "+----+-------------+--------------+\n",
      "|  3 | Delhi       | Delhi        |\n",
      "+----+-------------+--------------+\n",
      "|  4 | Orissa      | Bhubhaneswar |\n",
      "+----+-------------+--------------+\n",
      "|  5 | Gujrat      | Gandhinagar  |\n",
      "+----+-------------+--------------+\n",
      "R3 = ( U3 = {A,C}, F3 = {'A -> C'} )\n",
      "+----+-------------+---------+\n",
      "|    | A           | B       |\n",
      "+====+=============+=========+\n",
      "|  0 | State       | Doctors |\n",
      "+----+-------------+---------+\n",
      "|  1 | Maharashtra | 500     |\n",
      "+----+-------------+---------+\n",
      "|  2 | Rajasthan   | 200     |\n",
      "+----+-------------+---------+\n",
      "|  3 | Delhi       | 350     |\n",
      "+----+-------------+---------+\n",
      "|  4 | Orissa      | 200     |\n",
      "+----+-------------+---------+\n",
      "|  5 | Gujrat      | 300     |\n",
      "+----+-------------+---------+\n",
      "R4 = ( U4 = {A,B}, F4 = lack )\n",
      "--------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "relation_set = set()\n",
    "attributes = set()\n",
    "post_synthesis = dict()\n",
    "canonical_list = []\n",
    "domkniecia = {}\n",
    "key_attributes = set()\n",
    "non_key_attributes = set()\n",
    "minimal_keys = set()\n",
    "super_keys = set()\n",
    "closure_string = \"\"\n",
    "base_min = []\n",
    "destroy_2PN = []\n",
    "destroy_3PN = []\n",
    "\n",
    "\n",
    "\n",
    "#read the csv file\n",
    "df = pd.read_csv(\"DBMS - Sheet1.csv\")\n",
    "\n",
    "#get the number of columns \n",
    "number_of_columns = len(df.columns)\n",
    "alphabet_list = [chr(i) for i in range(65,65+number_of_columns)]\n",
    "\n",
    "print(\"The attributes are: \" + \", \".join(alphabet_list))\n",
    "\n",
    "print(\"Action: \")\n",
    "print(\"1 - entering attributes and relationships manually\")\n",
    "print(\"2 - loading attributes and relationships from the file\")\n",
    "print(\"Type any other character to exit\")\n",
    "option = '1'\n",
    "\n",
    "if(option == '1'):\n",
    "    print(\"Enter the attributes in one line, separating only with a comma.\")\n",
    "    print(\"Enter each functional dependency on a separate line. After entering all of them, also on a separate line, enter END to continue.\")\n",
    "    # load attributes\n",
    "    # input_attributes = input(\"Attributes: \").split(\",\")\n",
    "    attributes = set(alphabet_list)\n",
    "    # load functional dependencies\n",
    "\n",
    "    print(\"When entering functional dependencies, keep the format: attributes/y -> attributes/y, i.e. A,B -> D,C\")\n",
    "    print(\"Functional dependencies: \")\n",
    "    # line = \"\"\n",
    "    # while(line != \"END\"):\n",
    "    #     line = input()\n",
    "    #     if(line != \"END\"):\n",
    "    #         relation_set.add(line)\n",
    "    #read the inputs from the text file\n",
    "\n",
    "\n",
    "    #read the text file\n",
    "    with open(\"dbmstest.txt\") as f:\n",
    "        for line in f:\n",
    "            if(line != \"END\"):\n",
    "                line = line.rstrip()\n",
    "                relation_set.add(line)\n",
    "\n",
    "    #print the relations\n",
    "    print(\"Relations: \")\n",
    "    for x in relation_set:\n",
    "        print(x)\n",
    "\n",
    "\n",
    "                \n",
    "elif(option == '2'):\n",
    "    print(\"Select basic tests by entering a number from 01-10 (with a leading zero).\")\n",
    "    print(\"If you want to load your own test from a file, create a file in the folder with basic tests and name it and fill it in with the visible convention.\")\n",
    "    test_number = input(\"test number:\")\n",
    "    # support for reading from file\n",
    "    path = \"testy/test-\" + test_number + \".txt\"\n",
    "    test = open(path, \"r\")\n",
    "    attributesLine = test.readline().split(',')\n",
    "    # reads the attributes into the file - remove any duplicates immediately\n",
    "    for x in attributesLine:\n",
    "        attributes.add(x.strip())\n",
    "    # loads functional dependencies into the set - remove any duplicates immediately\n",
    "    for x in test:\n",
    "        x = x.rstrip()\n",
    "        relation_set.add(x)\n",
    "else:\n",
    "    pass\n",
    "\n",
    "# end setup #\n",
    "# attributes and functional dependencies are already loaded, the next step is to check the correctness of the loaded data, if the verification of inclusions F in U and U in F is not successful, the program will fail\n",
    "print(\"--------------------------------------------------------------------------------------------------------------------------------\")\n",
    "print(\"[ANALYSIS - START]\")\n",
    "print(\"Attributes: \" + ','.join(sorted(attributes)))\n",
    "print(\"Functional dependencies: \")\n",
    "for x in sorted(relation_set):\n",
    "    print(x)\n",
    "\n",
    "relations_dict = {}\n",
    "canonical_base = {}\n",
    "\n",
    "\n",
    "# load the dependency into the dictionary, left is the key - right is the set, then\n",
    "#A,B -> C\n",
    "#A,B -> D\n",
    "# in the dictionary this will be the key A,B: ['C','D'] (as set) on the right\n",
    "for relation in relation_set:\n",
    "    left = relation.rsplit('-')[0].strip()\n",
    "    del_repeat = sorted(set(left.split(\",\")))\n",
    "    left = \",\".join(del_repeat)\n",
    "    canonical_base[left] = set()\n",
    "\n",
    "for relation in relation_set:\n",
    "    left = relation.rsplit('-')[0].strip()\n",
    "    right = relation.rsplit('>')[1].strip()\n",
    "\n",
    "    del_repeat = sorted(set(left.split(\",\")))\n",
    "    left = \",\".join(del_repeat)\n",
    "\n",
    "    relations_dict[left] = right\n",
    "\n",
    "    # exploding e.g. A -> B,C into A -> B; A -> C\n",
    "\n",
    "    rightAttributes = right.split(\",\")\n",
    "    for i in rightAttributes:\n",
    "        canonical_base[left].add(i.strip())\n",
    "\n",
    "# after loading everything into the dictionary, I am sure that I don't have duplicates anymore, I can go to the list and from it to the canonical form\n",
    "canonical_list = []\n",
    "for i in canonical_base:\n",
    "    right_values = canonical_base[i]\n",
    "    for j in right_values:\n",
    "        canonical_list.append([i, j])\n",
    "\n",
    "print(\"\")\n",
    "print(\"[VERIFICATION]\")\n",
    "fun_F = set()\n",
    "# here can be on the left e.g. A,B,C,D -> E therefore split()\n",
    "for x in canonical_base:\n",
    "    attr_in_F = x.split(\",\")\n",
    "    for y in attr_in_F:\n",
    "        fun_F.add(y)\n",
    "\n",
    "for x in canonical_base.values():\n",
    "    attr_in_F = x\n",
    "    for y in attr_in_F:\n",
    "        fun_F.add(y)\n",
    "\n",
    "print(\"Attributes with U: \" + \", \".join(sorted(attributes)))\n",
    "print(\"Attributes from F: \" + \", \".join(sorted(fun_F)))\n",
    "\n",
    "# VERIFYING THE CORRECTNESS OF INPUT DATA\n",
    "if(attributes.issubset(fun_F) == False):\n",
    "    print(\"There is at least one attribute in U that is not in F. Adds a trivial dependency.\")\n",
    "    for x in attributes:\n",
    "        if x not in fun_F:\n",
    "            print(x + \" -> \" + x)\n",
    "    print(\"--------------------------------------------------------------------------------------------------------------------------------\")\n",
    "if (fun_F.issubset(attributes) == False):\n",
    "    print(\"There is at least one attribute in F that is not in U. Verification failed.\")\n",
    "    print(\"--------------------------------------------------------------------------------------------------------------------------------\")\n",
    "else:\n",
    "    print(\"The attributes in F and U match. Verification successful.\")\n",
    "    print(\"\")\n",
    "    # remember all keys - no division\n",
    "    all_keys = keys_gen(attributes, canonical_list)\n",
    "    # extract minimal candidate keys\n",
    "    extract_minimal(all_keys)\n",
    "    # print closures\n",
    "    key_attributes = sorted(list_closure(attributes, canonical_base))\n",
    "    # list attributes broken down into key and non-key\n",
    "    print(\"\")\n",
    "    print(\"[DETERMINATION OF ATTRIBUTES]\")\n",
    "    attributes_specification()\n",
    "    print(\"\")\n",
    "    print(\"[MINIMUM BASE]\")\n",
    "    minimal_base(canonical_list)\n",
    "    print(\"\")\n",
    "    print(\"[TEST ON 2PN]\")\n",
    "    if(not is2PN()):\n",
    "        print(\"\"\"The relation is not in 2 normal form.\n",
    "For a relation to be in 2PN, it is necessary that each non-key attribute is fully functionally dependent on each key of that relation.\n",
    "In the given scheme, there is more pleasantly one partial functional dependency that violates 2PN.\n",
    "These dependencies are:\"\"\")\n",
    "        for x in destroy_2PN:\n",
    "            print(x[0] + \" -> \" + x[1])\n",
    "    else:\n",
    "        print(\"The relation is in 2 normal form.\")\n",
    "    if(not is3PN()):\n",
    "        print(\"\")\n",
    "        print(\"For a relation to be in 3PN, it is necessary that, in addition to being in 2PN, each of its functional dependencies X -> Y has one of the following properties:\")\n",
    "        print(\"\"\"\n",
    "(1) the relationship is trivial (Y is contained in X) or\n",
    "(2) X is a superkey or\n",
    "(3) Y is a key attribute\n",
    "            \"\"\")\n",
    "        print(\"[TEST ON 3PN]\")\n",
    "        print(\"The relation is not in 3 normal form. Dependencies that do not meet any of the above conditions are: \")\n",
    "        for x in destroy_3PN:\n",
    "            print(x[0] + \" -> \" + x[1])\n",
    "        print(\"\")\n",
    "        print(\"[DECOMPOSITION BY SYNTHESIS]\")\n",
    "        synthesis(canonical_list,df)\n",
    "        print(\"--------------------------------------------------------------------------------------------------------------------------------\")\n",
    "    else:\n",
    "        print(\"The relation is in 3 normal form.\")\n",
    "        print(\"--------------------------------------------------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b4cfb76a11e0e84d4feeadacba1490f8b2894fce3ebdb9869aa53d8573c3b5dd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
